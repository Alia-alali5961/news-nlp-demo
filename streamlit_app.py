import streamlit as st
import nltk
from nltk.tokenize import word_tokenize
from nltk.util import ngrams
from nltk.probability import FreqDist
from nltk.lm import Laplace
from nltk.lm.preprocessing import padded_everygram_pipeline
import spacy
import re
import math
from collections import Counter

# --- Language Detection ---
def is_arabic(text):
    arabic_char_count = len(re.findall(r'[\u0600-\u06FF]', text))
    total_char_count = len(text)
    return arabic_char_count / max(total_char_count, 1) > 0.2

# --- Preprocess & Tokenize ---
def preprocess_and_tokenize(text, lang):
    if lang == 'en':
        text = text.lower()
        tokens = word_tokenize(text)
        tokens = [w for w in tokens if w.isalnum()]
    elif lang == 'ar':
        # Normalize and simple tokenization
        text = re.sub(r'[^\u0600-\u06FF\s]', '', text)
        tokens = re.findall(r'[\u0600-\u06FF]+', text)
    else:
        tokens = []
    return tokens

# --- Rule-based POS Tagging (for Arabic) ---
def arabic_pos_rulebased(tokens):
    pos_tags = []
    for token in tokens:
        if re.match(r'^[Ø§Ù„].+', token):       # starts with "Ø§Ù„" (the) â†’ likely noun
            pos_tags.append((token, 'NOUN'))
        elif len(token) <= 2:                 # short words â†’ possible prepositions or particles
            pos_tags.append((token, 'PART'))
        elif token.endswith('Ø©') or token.endswith('Ø§Øª'):
            pos_tags.append((token, 'NOUN'))
        elif token.endswith('ÙŠ') or token.endswith('Ùƒ') or token.endswith('Ù‡Ù…'):
            pos_tags.append((token, 'PRON'))
        elif token.endswith('ÙˆÙ†') or token.endswith('ÙŠÙ†'):
            pos_tags.append((token, 'VERB'))
        else:
            pos_tags.append((token, 'OTHER'))
    return pos_tags

def pos_tagging(tokens, lang):
    if lang == 'en':
        return nltk.pos_tag(tokens)
    elif lang == 'ar':
        return arabic_pos_rulebased(tokens)
    return []

# --- N-gram Analysis ---
def n_gram_analysis(tokens, n=2):
    n_grams = list(ngrams(tokens, n))
    freq_dist = FreqDist(n_grams)
    return freq_dist.most_common(10)

# --- Perplexity (simplified) ---
def calculate_perplexity(tokens):
    if len(tokens) < 5:
        return "Not enough tokens to calculate perplexity."
    train_data, vocab = padded_everygram_pipeline(2, [tokens])
    lm = Laplace(2)
    lm.fit(train_data, vocab)
    test_data, _ = padded_everygram_pipeline(2, [tokens])
    ppx_list = []
    for sent_ngrams in test_data:
        try:
            val = lm.perplexity(sent_ngrams)
            if not math.isinf(val):
                ppx_list.append(val)
        except ZeroDivisionError:
            continue
    return f"{sum(ppx_list)/len(ppx_list):.2f}" if ppx_list else "N/A"

# --- spaCy for English ---
@st.cache_resource
def load_spacy_model():
    try:
        return spacy.load("en_core_web_sm")
    except OSError:
        st.error("spaCy model not found.")
        return None
nlp = load_spacy_model()

# --- Rule-based Arabic NER ---
def arabic_ner_rulebased(text):
    entities = []
    # Example simple rules
    if 'Ø§Ù„Ø¥Ù…Ø§Ø±Ø§Øª' in text or 'Ø¯Ø¨ÙŠ' in text or 'Ø£Ø¨ÙˆØ¸Ø¨ÙŠ' in text:
        entities.append(('Ø§Ù„Ø¥Ù…Ø§Ø±Ø§Øª', 'LOC'))
    if 'Ù…Ø­Ù…Ø¯' in text or 'Ø®Ø§Ù„Ø¯' in text:
        entities.append(('Ù…Ø­Ù…Ø¯', 'PER'))
    if 'Ø¬Ø§Ù…Ø¹Ø©' in text:
        entities.append(('Ø¬Ø§Ù…Ø¹Ø©', 'ORG'))
    return entities if entities else [('â€”', 'â€”')]

def ner_analysis(text, lang):
    if lang == 'en' and nlp:
        doc = nlp(text)
        return [(ent.text, ent.label_) for ent in doc.ents]
    elif lang == 'ar':
        return arabic_ner_rulebased(text)
    return []

# --- Streamlit UI ---
def main():
    st.set_page_config(page_title="News NLP Web Demo", page_icon="ðŸ—žï¸", layout="wide")
    
    # Hero header
    st.markdown("# ðŸ—žï¸ News NLP Web Demo â€” Arabicâ€“English pipeline (paste text or URL)")
    
    # Create tabs
    tab_demo, tab_about, tab_credits = st.tabs(["Demo", "About", "Credits"])
    
    with tab_demo:
        st.title("ðŸ“° Arabicâ€“English News NLP Pipeline")
        st.markdown("Enter newspaper text below to analyze using rule-based Arabic + spaCy/NLTK English pipeline.")
        
        text = st.text_area("Enter text:", height=250, value="Ø´Ø±ÙƒØ© Ø£Ø¨Ù„ Ù‡ÙŠ Ø´Ø±ÙƒØ© ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ù…Ù‚Ø±Ù‡Ø§ ÙƒØ§Ù„ÙŠÙÙˆØ±Ù†ÙŠØ§. Ù…Ø­Ù…Ø¯ ÙŠØ¹Ù…Ù„ Ù‡Ù†Ø§Ùƒ.")
        if st.button("Apply NLP Pipeline"):
            lang = 'ar' if is_arabic(text) else 'en'
            st.info(f"Detected language: **{'Arabic' if lang == 'ar' else 'English'}**")
            
            tokens = preprocess_and_tokenize(text, lang)
            if not tokens:
                st.warning("No tokens found.")
                return
            
            # POS
            with st.expander("1ï¸âƒ£ POS Tagging", expanded=True):
                pos_tags = pos_tagging(tokens, lang)
                st.dataframe([{"Token": t, "POS": p} for t, p in pos_tags])
            
            # N-gram
            with st.expander("2ï¸âƒ£ Top 10 Bigrams", expanded=True):
                ngrams_list = n_gram_analysis(tokens, n=2)
                st.dataframe([{"Bigram": " ".join(bg), "Freq": f} for bg, f in ngrams_list])
            
            # Perplexity
            with st.expander("3ï¸âƒ£ Perplexity (Demo)", expanded=True):
                score = calculate_perplexity(tokens)
                st.write(f"**Perplexity:** {score}")
            
            # NER
            with st.expander("4ï¸âƒ£ Named Entity Recognition (NER)", expanded=True):
                ents = ner_analysis(text, lang)
                st.dataframe([{"Entity": e, "Type": t} for e, t in ents])
    
    with tab_about:
        st.markdown("""
        This demo runs an Arabicâ€“English News NLP pipeline. Paste text or a URL to detect language, classify/score, and view key terms and a short summary. Student prototypeâ€”results may be imperfect.
        """)
    
    with tab_credits:
        st.markdown("""
        **Group Members:** Alia Al Ali; Aya Ehab; Rana Kamal Eldin; Reem Bin Haider; Salma Amarah
        
        **Affiliation:** The British University in Dubai (BUiD)
        
        **Copyright:** Â© 2025 Alia Al Ali, Aya Ehab, Rana Kamal Eldin, Reem Bin Haider, Salma Amarah. All rights reserved.
        """)
    
    # Footer
    st.markdown("---")
    st.markdown("**Built with Streamlit â€¢ Demo v1.0**")

if __name__ == "__main__":
    main()
